# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=kafka-test

# YARN
yarn.package.path={$PATH_TO_PACKAGE}
# Task
task.class=stateful.streaming.process.MyTask
# The job consumes a topic called "PageViewEvent" from the "kafka" system
task.inputs=kafka.testWord
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
# Normally, this would be 3, but we have only one broker.
task.checkpoint.replication.factor=1

# Window task's interval
task.window.ms=300000

# Serializer/Deserializer
#serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory


# Kafka
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=string
systems.kafka.streams.PageViewEvent.samza.msg.serde=string
systems.kafka.consumer.zookeeper.connect={$ZK_HOST}
systems.kafka.producer.metadata.broker.list={$BROKER_LIST}
systems.kafka.producer.producer.type=sync
# Normally, we'd set this much higher, but we want things to look snappy in the demo.
systems.kafka.producer.batch.num.messages=1

# Remote debug
task.opts=-agentlib:jdwp=transport=dt_socket,address=9009,server=y,suspend=n

# Use the "json" serializer for messages in the "PageViewEvent" topic
#systems.kafka.streams.PageViewEvent.samza.msg.serde=json

# Store
stores.meta-counter.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.meta-counter.changelog=kafka.meta-counter-changelog
stores.meta-counter.key.serde=string
stores.meta-counter.msg.serde=string
stores.meta-counter.write.batch.size=500
stores.meta-counter.object.cache.size=1000